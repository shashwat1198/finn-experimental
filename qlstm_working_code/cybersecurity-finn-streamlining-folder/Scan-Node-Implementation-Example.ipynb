{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa93fb9",
   "metadata": {},
   "source": [
    "Some general points and observations regarding the `Scan` node in ONNX:\n",
    "\n",
    "1. Scan can be used to iterate over one or more scan input tensors constructing zero or more scan output tensors. Combines ideas from general recurrences, functional programming cnostructs such as scan, fold, map and zip.\n",
    "2. The attribute `body` in the node must be a graph specifying the computation to be performed in every iteration.\n",
    "3. Input is the current values of the `state variables` and the current `iterated element` of the scan input. Returns values of the `state variables` and the `scan output element tensors`. (Can be greater than 1)\n",
    "4. The values of the scan output tensors are concatenated over all the iterations to produce the scan output values of the scan construct.\n",
    "5. The properties that make a scan node unique and different from a normal compute node are:\n",
    "* Update the hidden state variable after each input computation; to be used in the processing of the next input.\n",
    "* It needs to scan your inputs row by row or column by column; then keep computing the output with the updated hidden state for every input; while storing all the intermediate outputs in the form of hidden states.\n",
    "\n",
    "In this example, I am implementing one of the six equations used to solve for an LSTM output.\n",
    "\n",
    "    g_out = W * X + U * h_t-1 + b\n",
    "\n",
    "* Here, `g_out` is the output of one of the four gates involved in the LSTM equations.\n",
    "* `X` is the input, `h_t-1` is the previous hidden state.\n",
    "* `W`, `U` and `b` are the weight matrix, recurrence matrix and the bias for that gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22bb85f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import numpy as np\n",
    "from qonnx.util.basic import qonnx_make_model\n",
    "from finn.util.visualization import showInNetron\n",
    "import onnxruntime as rt\n",
    "from qonnx.util.basic import qonnx_make_model\n",
    "from onnx.helper import make_tensor_value_info, make_node, make_graph, make_model, make_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3398b8e",
   "metadata": {},
   "source": [
    "#### Part 1 : We first define the compute graph that we want to execute inside the `Scan` node. \n",
    "* Assuming the input size is 10 and the number of hidden states are 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18791d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ql_w = make_node(\"QuantizeLinear\", inputs=[\"W_s\",\"scale_all\",\"zero_point_all\"], outputs=[\"ql_ws\"], name=\"ql_w\")\n",
    "clp_w = make_node(\"Clip\", inputs=[\"ql_ws\",\"min\",\"max\"], outputs=[\"clp_ws\"], name=\"clp_ws\")\n",
    "dql_w = make_node(\"DequantizeLinear\", inputs=[\"clp_ws\",\"scale_all\",\"zero_point_all\"], outputs=[\"dql_ws\"], name=\"dql_w\")\n",
    "\n",
    "ql_u = make_node(\"QuantizeLinear\", inputs=[\"U_s\",\"scale_all\",\"zero_point_all\"], outputs=[\"ql_us\"], name=\"ql_u\")\n",
    "clp_u = make_node(\"Clip\", inputs=[\"ql_us\",\"min\",\"max\"], outputs=[\"clp_us\"], name=\"clp_u\")\n",
    "dql_u = make_node(\"DequantizeLinear\", inputs=[\"clp_us\",\"scale_all\",\"zero_point_all\"], outputs=[\"dql_us\"], name=\"dql_u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "807b56f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the inputs and outputs of the graph we need to create.\n",
    "# Input definition\n",
    "inp_X = make_tensor_value_info(\n",
    "\"X\",onnx.TensorProto.FLOAT, [10,1]\n",
    ")\n",
    "\n",
    "inp_h_t_1 = make_tensor_value_info(\n",
    "\"h_t-1\",onnx.TensorProto.FLOAT, [20,1]\n",
    ")\n",
    "\n",
    "#Output definition\n",
    "\n",
    "out_state = make_tensor_value_info(\n",
    "\"s_t\", onnx.TensorProto.FLOAT, [20,1]\n",
    ")\n",
    "\n",
    "scan_out = make_tensor_value_info(\n",
    "\"scan_out\", onnx.TensorProto.FLOAT, [20,1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36cfbfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the individual nodes of the graph we want to create.\n",
    "# --------------------------------------------\n",
    "mul_node1 = make_node(\n",
    "\"MatMul\", inputs=[\"dql_ws\",\"X\"], outputs=[\"out_m1\"], name=\"mul_node1\"\n",
    ")\n",
    "\n",
    "mul_node2 = make_node(\n",
    "\"MatMul\", inputs=[\"dql_us\",\"h_t-1\"], outputs=[\"out_m2\"],name=\"mul_node2\"\n",
    ")\n",
    "\n",
    "add_node1 =  make_node(\n",
    "\"Add\", inputs=[\"out_m1\",\"out_m2\"], outputs=[\"out_add1\"],name=\"add_node1\"\n",
    ")\n",
    "\n",
    "add_node2 = make_node(\n",
    "\"Add\", inputs=[\"out_add1\",\"b_s\"], outputs=[\"s_t_ba\"],name=\"add_node2\"\n",
    ")\n",
    "\n",
    "sig_s = make_node(\n",
    "\"Sigmoid\", inputs=[\"s_t_ba\"], outputs=[\"s_t\"],name=\"sig_s\"\n",
    ")\n",
    "\n",
    "id_node = make_node(\n",
    "\"Identity\", inputs=[\"s_t\"], outputs=[\"scan_out\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74d0ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_val = np.ones([20,1],dtype=np.float32).reshape([20,1])\n",
    "Ws_val = np.ones([20,10],dtype=np.float32).reshape([20,10])\n",
    "Us_val = np.ones([20,20],dtype=np.float32).reshape([20,20])\n",
    "gen_lstm_eq = onnx.helper.make_graph(\n",
    "    nodes=[\n",
    "           ql_w,\n",
    "           clp_w,\n",
    "           dql_w,\n",
    "           ql_u,\n",
    "           clp_u,\n",
    "           dql_u, \n",
    "           mul_node1, \n",
    "           mul_node2, \n",
    "           add_node1, \n",
    "           add_node2,\n",
    "           sig_s,\n",
    "           id_node\n",
    "          ],\n",
    "    name = \"Scan-Body\",\n",
    "    inputs=[inp_h_t_1,inp_X],#The order of the inputs reversed here in order to match the order of inputs of the defined scan node.\n",
    "    outputs = [out_state, scan_out],\n",
    "    value_info=[\n",
    "            make_tensor_value_info(\"out_m1\",onnx.TensorProto.FLOAT, [20,1]),\n",
    "            make_tensor_value_info(\"out_m2\",onnx.TensorProto.FLOAT, [20,1]),\n",
    "            make_tensor_value_info(\"out_add1\",onnx.TensorProto.FLOAT, [20,1]),\n",
    "            make_tensor_value_info(\"s_t_ba\",onnx.TensorProto.FLOAT, [20,1]),\n",
    "            make_tensor_value_info(\"ql_ws\", onnx.TensorProto.INT8, [20,10]),\n",
    "            make_tensor_value_info(\"dql_ws\",onnx.TensorProto.FLOAT, [20,10]),\n",
    "            make_tensor_value_info(\"ql_us\", onnx.TensorProto.INT8, [20,20]),\n",
    "            make_tensor_value_info(\"dql_us\",onnx.TensorProto.FLOAT, [20,20])\n",
    "        ],\n",
    "    initializer=[make_tensor('W_s',onnx.TensorProto.FLOAT, [20,10], (Ws_val)),\n",
    "                 make_tensor('U_s',onnx.TensorProto.FLOAT, [20,20], (Us_val)),\n",
    "                 make_tensor('b_s',onnx.TensorProto.FLOAT, [20,1], (bias_val)),\n",
    "                 make_tensor('scale_all',onnx.TensorProto.FLOAT,[],[1]),\n",
    "                 make_tensor('zero_point_all',onnx.TensorProto.INT8,[],[0]),\n",
    "                 make_tensor('min',onnx.TensorProto.INT8, [],[-7]),\n",
    "                 make_tensor('max',onnx.TensorProto.INT8, [], [7]),\n",
    "                 make_tensor('bitwidth',onnx.TensorProto.INT32, [], [4])\n",
    "                ]\n",
    ")\n",
    "#So some points to note here:\n",
    "#1. Initializers ('W_s','U_s' and 'b_s') are a part of the model and they will not be defined in the list of the inputs.\n",
    "#2. Because they are a part of the model, these initializers will not be defined again when we define the scan node later, which we will see.\n",
    "#3. Scan node only cares about the inputs and outputs of the body_graph and does not care what happens inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1143b778",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "onnx_model = qonnx_make_model(gen_lstm_eq, producer_name=\"LSTM_eq\")\n",
    "onnx.save(onnx_model, './gen_lstm_eq.onnx')\n",
    "#showInNetron('./gen_lstm_eq.onnx')#,localhost_url='xirxlabs53'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ed90c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have to convert the opset version of the graph here because the clip operator in the previous version did not allow for INT8 inputs.\n",
    "# It only allowed for FLOAT inputs.\n",
    "from onnx import version_converter, helper\n",
    "onnx_model_14 = version_converter.convert_version(onnx_model, 14)\n",
    "# print(onnx_model_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d218624c",
   "metadata": {},
   "source": [
    "Testing the above graph with `onnxruntime` execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31b8bd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586]], dtype=float32), array([[0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586],\n",
      "       [0.7310586]], dtype=float32)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 10:10:56.548822729 [W:onnxruntime:, graph.cc:3543 CleanUnusedInitializersAndNodeArgs] Removing initializer 'bitwidth'. It is not used by any node and should be removed from the model.\n"
     ]
    }
   ],
   "source": [
    "in_X = np.asarray(np.random.randint(low=0, high=1, size=(10,1)), dtype=np.float32)\n",
    "in_h_t_1 = np.asarray(np.random.randint(low=0, high=1, size=(20,1)), dtype=np.float32)\n",
    "input_dict = {}\n",
    "input_dict[\"X\"] = in_X\n",
    "input_dict[\"h_t-1\"] = in_h_t_1\n",
    "\n",
    "sess = rt.InferenceSession(onnx_model_14.SerializeToString())\n",
    "output = sess.run(None, input_dict)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1d7009",
   "metadata": {},
   "source": [
    "#### Part 2 : Now defining the scan node.\n",
    "\n",
    "The node will incorporate the above graph we defined. \n",
    "\n",
    "* The input to the node with be the current input `X` and the previous `hidden_state`\n",
    "* The output of the node will be the a tensor with the `final_state` of the gate and a tensor with all the `intermediate_states` of the gate computed for each input. {Replicating what we need in our LSTM compute where the output tensors are the `final_cell_state`, `final_hidden_state` and all the `concatenated_hidden_states`}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b692d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the input and output value info tensors for the scan_graph creation. These tensors act as the wrapper to the previously defined graph.\n",
    "\n",
    "#Inputs\n",
    "scan_input = make_tensor_value_info(\n",
    "\"scan_input\",onnx.TensorProto.FLOAT, [None,10,1]\n",
    ")#X ; scan input; Here 'None' defines the varibale number of inputs that can be supplied for input processing.\n",
    "\n",
    "inp_a = make_tensor_value_info(\n",
    "\"inp_a\",onnx.TensorProto.FLOAT, [20,1]\n",
    ")# h_t-1\n",
    "\n",
    "#Outputs\n",
    "out_a = make_tensor_value_info(\n",
    "\"out_a\", onnx.TensorProto.FLOAT, [20,1]\n",
    ")#s_t\n",
    "\n",
    "out_b = make_tensor_value_info(\n",
    "\"out_b\", onnx.TensorProto.FLOAT, [None,20,1]\n",
    ")#scan_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e66825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the scan node here now\n",
    "scan_node_gen_lstm_eq = make_node(\n",
    "    \"Scan\", inputs=[\"inp_a\",\"scan_input\"], \n",
    "    outputs=[\"out_a\",\"out_b\"], \n",
    "    num_scan_inputs=1,\n",
    "    body=gen_lstm_eq, domain=''\n",
    ")# The order in which the nodes are defined in the inputs and outputs also matter here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec0b7e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_lstm_scan_graph = make_graph(\n",
    "    nodes = [scan_node_gen_lstm_eq],\n",
    "    name=\"gen_eq_graph\",\n",
    "    inputs=[inp_a,scan_input],\n",
    "    outputs=[out_a,out_b]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b49eba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_version: 8\n",
      "producer_name: \"eq-model\"\n",
      "graph {\n",
      "  node {\n",
      "    input: \"inp_a\"\n",
      "    input: \"scan_input\"\n",
      "    output: \"out_a\"\n",
      "    output: \"out_b\"\n",
      "    op_type: \"Scan\"\n",
      "    attribute {\n",
      "      name: \"body\"\n",
      "      g {\n",
      "        node {\n",
      "          input: \"W_s\"\n",
      "          input: \"scale_all\"\n",
      "          input: \"zero_point_all\"\n",
      "          output: \"ql_ws\"\n",
      "          name: \"ql_w\"\n",
      "          op_type: \"QuantizeLinear\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"ql_ws\"\n",
      "          input: \"min\"\n",
      "          input: \"max\"\n",
      "          output: \"clp_ws\"\n",
      "          name: \"clp_ws\"\n",
      "          op_type: \"Clip\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"clp_ws\"\n",
      "          input: \"scale_all\"\n",
      "          input: \"zero_point_all\"\n",
      "          output: \"dql_ws\"\n",
      "          name: \"dql_w\"\n",
      "          op_type: \"DequantizeLinear\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"U_s\"\n",
      "          input: \"scale_all\"\n",
      "          input: \"zero_point_all\"\n",
      "          output: \"ql_us\"\n",
      "          name: \"ql_u\"\n",
      "          op_type: \"QuantizeLinear\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"ql_us\"\n",
      "          input: \"min\"\n",
      "          input: \"max\"\n",
      "          output: \"clp_us\"\n",
      "          name: \"clp_u\"\n",
      "          op_type: \"Clip\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"clp_us\"\n",
      "          input: \"scale_all\"\n",
      "          input: \"zero_point_all\"\n",
      "          output: \"dql_us\"\n",
      "          name: \"dql_u\"\n",
      "          op_type: \"DequantizeLinear\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"dql_ws\"\n",
      "          input: \"X\"\n",
      "          output: \"out_m1\"\n",
      "          name: \"mul_node1\"\n",
      "          op_type: \"MatMul\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"dql_us\"\n",
      "          input: \"h_t-1\"\n",
      "          output: \"out_m2\"\n",
      "          name: \"mul_node2\"\n",
      "          op_type: \"MatMul\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"out_m1\"\n",
      "          input: \"out_m2\"\n",
      "          output: \"out_add1\"\n",
      "          name: \"add_node1\"\n",
      "          op_type: \"Add\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"out_add1\"\n",
      "          input: \"b_s\"\n",
      "          output: \"s_t_ba\"\n",
      "          name: \"add_node2\"\n",
      "          op_type: \"Add\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"s_t_ba\"\n",
      "          output: \"s_t\"\n",
      "          name: \"sig_s\"\n",
      "          op_type: \"Sigmoid\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"s_t\"\n",
      "          output: \"scan_out\"\n",
      "          op_type: \"Identity\"\n",
      "        }\n",
      "        name: \"Scan-Body\"\n",
      "        initializer {\n",
      "          dims: 20\n",
      "          dims: 10\n",
      "          data_type: 1\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          name: \"W_s\"\n",
      "        }\n",
      "        initializer {\n",
      "          dims: 20\n",
      "          dims: 20\n",
      "          data_type: 1\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          name: \"U_s\"\n",
      "        }\n",
      "        initializer {\n",
      "          dims: 20\n",
      "          dims: 1\n",
      "          data_type: 1\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          name: \"b_s\"\n",
      "        }\n",
      "        initializer {\n",
      "          data_type: 1\n",
      "          float_data: 1.0\n",
      "          name: \"scale_all\"\n",
      "        }\n",
      "        initializer {\n",
      "          data_type: 3\n",
      "          int32_data: 0\n",
      "          name: \"zero_point_all\"\n",
      "        }\n",
      "        initializer {\n",
      "          data_type: 3\n",
      "          int32_data: -7\n",
      "          name: \"min\"\n",
      "        }\n",
      "        initializer {\n",
      "          data_type: 3\n",
      "          int32_data: 7\n",
      "          name: \"max\"\n",
      "        }\n",
      "        initializer {\n",
      "          data_type: 6\n",
      "          int32_data: 4\n",
      "          name: \"bitwidth\"\n",
      "        }\n",
      "        input {\n",
      "          name: \"h_t-1\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        input {\n",
      "          name: \"X\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 10\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        output {\n",
      "          name: \"s_t\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        output {\n",
      "          name: \"scan_out\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"out_m1\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"out_m2\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"out_add1\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"s_t_ba\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"ql_ws\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 3\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 10\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"dql_ws\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 10\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"ql_us\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 3\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"dql_us\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      type: GRAPH\n",
      "    }\n",
      "    attribute {\n",
      "      name: \"num_scan_inputs\"\n",
      "      i: 1\n",
      "      type: INT\n",
      "    }\n",
      "    domain: \"\"\n",
      "  }\n",
      "  name: \"gen_eq_graph\"\n",
      "  input {\n",
      "    name: \"inp_a\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "            dim_value: 20\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"scan_input\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 10\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"out_a\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "            dim_value: 20\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"out_b\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 20\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "opset_import {\n",
      "  domain: \"\"\n",
      "  version: 11\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gen_scan_model = qonnx_make_model(gen_lstm_scan_graph, producer_name=\"eq-model\")\n",
    "onnx.save(gen_scan_model, './gen_scan_model.onnx')\n",
    "print(gen_scan_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8c1f9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ir_version: 8\n",
      "producer_name: \"eq-model\"\n",
      "graph {\n",
      "  node {\n",
      "    input: \"inp_a\"\n",
      "    input: \"scan_input\"\n",
      "    output: \"out_a\"\n",
      "    output: \"out_b\"\n",
      "    op_type: \"Scan\"\n",
      "    attribute {\n",
      "      name: \"body\"\n",
      "      g {\n",
      "        node {\n",
      "          input: \"W_s\"\n",
      "          input: \"scale_all\"\n",
      "          input: \"zero_point_all\"\n",
      "          output: \"ql_ws\"\n",
      "          name: \"ql_w\"\n",
      "          op_type: \"QuantizeLinear\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"ql_ws\"\n",
      "          input: \"min\"\n",
      "          input: \"max\"\n",
      "          output: \"clp_ws\"\n",
      "          name: \"clp_ws\"\n",
      "          op_type: \"Clip\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"clp_ws\"\n",
      "          input: \"scale_all\"\n",
      "          input: \"zero_point_all\"\n",
      "          output: \"dql_ws\"\n",
      "          name: \"dql_w\"\n",
      "          op_type: \"DequantizeLinear\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"U_s\"\n",
      "          input: \"scale_all\"\n",
      "          input: \"zero_point_all\"\n",
      "          output: \"ql_us\"\n",
      "          name: \"ql_u\"\n",
      "          op_type: \"QuantizeLinear\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"ql_us\"\n",
      "          input: \"min\"\n",
      "          input: \"max\"\n",
      "          output: \"clp_us\"\n",
      "          name: \"clp_u\"\n",
      "          op_type: \"Clip\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"clp_us\"\n",
      "          input: \"scale_all\"\n",
      "          input: \"zero_point_all\"\n",
      "          output: \"dql_us\"\n",
      "          name: \"dql_u\"\n",
      "          op_type: \"DequantizeLinear\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"dql_ws\"\n",
      "          input: \"X\"\n",
      "          output: \"out_m1\"\n",
      "          name: \"mul_node1\"\n",
      "          op_type: \"MatMul\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"dql_us\"\n",
      "          input: \"h_t-1\"\n",
      "          output: \"out_m2\"\n",
      "          name: \"mul_node2\"\n",
      "          op_type: \"MatMul\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"out_m1\"\n",
      "          input: \"out_m2\"\n",
      "          output: \"out_add1\"\n",
      "          name: \"add_node1\"\n",
      "          op_type: \"Add\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"out_add1\"\n",
      "          input: \"b_s\"\n",
      "          output: \"s_t_ba\"\n",
      "          name: \"add_node2\"\n",
      "          op_type: \"Add\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"s_t_ba\"\n",
      "          output: \"s_t\"\n",
      "          name: \"sig_s\"\n",
      "          op_type: \"Sigmoid\"\n",
      "        }\n",
      "        node {\n",
      "          input: \"s_t\"\n",
      "          output: \"scan_out\"\n",
      "          op_type: \"Identity\"\n",
      "        }\n",
      "        name: \"Scan-Body\"\n",
      "        initializer {\n",
      "          dims: 20\n",
      "          dims: 10\n",
      "          data_type: 1\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          name: \"W_s\"\n",
      "        }\n",
      "        initializer {\n",
      "          dims: 20\n",
      "          dims: 20\n",
      "          data_type: 1\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          name: \"U_s\"\n",
      "        }\n",
      "        initializer {\n",
      "          dims: 20\n",
      "          dims: 1\n",
      "          data_type: 1\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          float_data: 1.0\n",
      "          name: \"b_s\"\n",
      "        }\n",
      "        initializer {\n",
      "          data_type: 1\n",
      "          float_data: 1.0\n",
      "          name: \"scale_all\"\n",
      "        }\n",
      "        initializer {\n",
      "          data_type: 3\n",
      "          int32_data: 0\n",
      "          name: \"zero_point_all\"\n",
      "        }\n",
      "        initializer {\n",
      "          data_type: 3\n",
      "          int32_data: -7\n",
      "          name: \"min\"\n",
      "        }\n",
      "        initializer {\n",
      "          data_type: 3\n",
      "          int32_data: 7\n",
      "          name: \"max\"\n",
      "        }\n",
      "        initializer {\n",
      "          data_type: 6\n",
      "          int32_data: 4\n",
      "          name: \"bitwidth\"\n",
      "        }\n",
      "        input {\n",
      "          name: \"h_t-1\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        input {\n",
      "          name: \"X\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 10\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        output {\n",
      "          name: \"s_t\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        output {\n",
      "          name: \"scan_out\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"ql_ws\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 3\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 10\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"clp_ws\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 3\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 10\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"dql_ws\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 10\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"ql_us\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 3\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"clp_us\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 3\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"dql_us\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"out_m1\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"out_m2\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"out_add1\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "        value_info {\n",
      "          name: \"s_t_ba\"\n",
      "          type {\n",
      "            tensor_type {\n",
      "              elem_type: 1\n",
      "              shape {\n",
      "                dim {\n",
      "                  dim_value: 20\n",
      "                }\n",
      "                dim {\n",
      "                  dim_value: 1\n",
      "                }\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "      type: GRAPH\n",
      "    }\n",
      "    attribute {\n",
      "      name: \"num_scan_inputs\"\n",
      "      i: 1\n",
      "      type: INT\n",
      "    }\n",
      "    domain: \"\"\n",
      "  }\n",
      "  name: \"gen_eq_graph\"\n",
      "  input {\n",
      "    name: \"inp_a\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "            dim_value: 20\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  input {\n",
      "    name: \"scan_input\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 10\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"out_a\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "            dim_value: 20\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  output {\n",
      "    name: \"out_b\"\n",
      "    type {\n",
      "      tensor_type {\n",
      "        elem_type: 1\n",
      "        shape {\n",
      "          dim {\n",
      "            dim_param: \"unk__0\"\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 20\n",
      "          }\n",
      "          dim {\n",
      "            dim_value: 1\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "opset_import {\n",
      "  domain: \"\"\n",
      "  version: 14\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Have to convert the opset version of the graph here because the clip operator in the previous version did not allow for INT8 inputs.\n",
    "# It only allowed for FLOAT inputs.\n",
    "from onnx import version_converter, helper\n",
    "gen_scan_model_14 = version_converter.convert_version(gen_scan_model, 14)\n",
    "print(gen_scan_model_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc2d40c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#Checking the model for any errors.\n",
    "onnx.checker.check_model(gen_scan_model_14)\n",
    "print(gen_scan_model.graph.value_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "555c4857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:5901\n",
      "Serving './gen_scan_model.onnx' at http://0.0.0.0:5901\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:5901/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff111b76970>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron('./gen_scan_model.onnx')#localhost_url='xirxlabs53'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5fedfb",
   "metadata": {},
   "source": [
    "Testing this new scan node with `3 inputs`. {Can change this to any number to execute `n` number of inputs.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4a28dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Hidden State :  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "All intermediate hidden states :  [[[0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]\n",
      "  [0.7310586]]\n",
      "\n",
      " [[0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]\n",
      "  [0.9999999]]\n",
      "\n",
      " [[1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]\n",
      "  [1.       ]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-12 10:11:23.265230994 [W:onnxruntime:, graph.cc:3543 CleanUnusedInitializersAndNodeArgs] Removing initializer 'bitwidth'. It is not used by any node and should be removed from the model.\n",
      "2023-10-12 10:11:23.267105686 [W:onnxruntime:, graph.cc:3543 CleanUnusedInitializersAndNodeArgs] Removing initializer 'ql_ws'. It is not used by any node and should be removed from the model.\n",
      "2023-10-12 10:11:23.267140631 [W:onnxruntime:, graph.cc:3543 CleanUnusedInitializersAndNodeArgs] Removing initializer 'ql_us'. It is not used by any node and should be removed from the model.\n",
      "2023-10-12 10:11:23.267167421 [W:onnxruntime:, graph.cc:3543 CleanUnusedInitializersAndNodeArgs] Removing initializer 'max'. It is not used by any node and should be removed from the model.\n",
      "2023-10-12 10:11:23.267193620 [W:onnxruntime:, graph.cc:3543 CleanUnusedInitializersAndNodeArgs] Removing initializer 'min'. It is not used by any node and should be removed from the model.\n",
      "2023-10-12 10:11:23.267220034 [W:onnxruntime:, graph.cc:3543 CleanUnusedInitializersAndNodeArgs] Removing initializer 'U_s'. It is not used by any node and should be removed from the model.\n",
      "2023-10-12 10:11:23.267246275 [W:onnxruntime:, graph.cc:3543 CleanUnusedInitializersAndNodeArgs] Removing initializer 'W_s'. It is not used by any node and should be removed from the model.\n"
     ]
    }
   ],
   "source": [
    "n = 3\n",
    "scan_inp_X = np.asarray(np.random.randint(low=0, high=1, size=(n,10,1)), dtype=np.float32)\n",
    "scan_inp_h_t_1 = np.asarray(np.random.randint(low=0, high=1, size=(20,1)), dtype=np.float32)\n",
    "input_dict = {}\n",
    "input_dict[\"scan_input\"] = scan_inp_X\n",
    "input_dict[\"inp_a\"] = scan_inp_h_t_1\n",
    "\n",
    "sess = rt.InferenceSession(gen_scan_model_14.SerializeToString())\n",
    "output = sess.run(None, input_dict)\n",
    "print('Final Hidden State : ',output[0])\n",
    "print('All intermediate hidden states : ', output[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb1ea4",
   "metadata": {},
   "source": [
    "The first output tensor is the `final_hidden_state` and the second output tensor are all the `n_intermediate_states` {including the final_hidden_state}."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73b191e1-5c61-4e41-afe9-a10bfa5e8f96",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
